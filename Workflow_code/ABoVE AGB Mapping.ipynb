{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53423e9e-97d7-4066-83d8-924504b2a93f",
   "metadata": {},
   "source": [
    "### This Jupyter Notebook demonstrates the key steps and corresponding Python code used for ABoVE Aboveground Biomass (AGB) mapping across the Arctic and Boreal regions of North America. For any questions, please contact wliangpudding@gmail.com or liangwan127@outlook.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86759f-bddc-4886-b883-0ce84fec8346",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1: calculate annual seasonal spectral featurs from CCDC  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3accd-a5f1-493e-aa57-ec8eed21f490",
   "metadata": {},
   "source": [
    "### Fitted CCDC parameters were obtained from GEE assets 'projects/CCDC/measures/v1_overlap''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2263a-c1d7-4add-9921-591a27d81c02",
   "metadata": {},
   "source": [
    "### Import key python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0989e9a6-b7f1-4cda-9376-9c64edf2a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc37b09-5be6-42f9-836c-8925b5a1130c",
   "metadata": {},
   "source": [
    "### Define functions needed to derive annual seasonal spectral features from CCDC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b989a6-07d9-4e86-ab97-187252a3ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_TO_DAYS = 86400000  # Number of milliseconds in a day\n",
    "EPOCH_DAYS = 719163    # Days from Julian calendar start (0000-01-01) to Unix epoch (1970-01-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8d5f53-428c-4e37-b786-ae7900e1ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_indices(ccd_names):\n",
    "    startBands_indices = [i for i, name in enumerate(ccd_names) if '_tStart' in name]\n",
    "    endBands_indices = [i for i, name in enumerate(ccd_names) if '_tEnd' in name]\n",
    "    return startBands_indices, endBands_indices\n",
    "\n",
    "def filterCoefs(ccd_names, ccd_results, date, band, coef, startBands_indices, endBands_indices):\n",
    "\n",
    "    coefBands_indices = [index for index, name in enumerate(ccd_names) if ((band in name)&(name.split('_')[-1]==coef))]\n",
    "    start_bands = ccd_results[startBands_indices,:,:]\n",
    "    end_bands = ccd_results[endBands_indices,:,:]\n",
    "    coef_bands = ccd_results[coefBands_indices,:,:]\n",
    "\n",
    "    start_bands[start_bands ==0.] = np.nan\n",
    "    end_bands[end_bands ==0.] = np.nan\n",
    "\n",
    "    segment_match_after = end_bands > date\n",
    "    first_true_indices = np.argmax(segment_match_after, axis=0)\n",
    "    bool_mask = segment_match_after == True\n",
    "    no_true_value = ~np.any(bool_mask, axis=0)\n",
    "\n",
    "    rows, cols = np.indices((coef_bands.shape[1], coef_bands.shape[2]))\n",
    "    # Use these indices to select from coef_bands\n",
    "    out_coef_after = coef_bands[first_true_indices, rows, cols]\n",
    "    out_coef_after = np.where(no_true_value, np.nan, out_coef_after)\n",
    "\n",
    "    segment_match_before = start_bands < date\n",
    "    first_false_indices = np.argmin(segment_match_before, axis=0)\n",
    "    last_true_indices = first_false_indices - 1\n",
    "    rows, cols =  np.indices((coef_bands.shape[1], coef_bands.shape[2]))\n",
    "    out_coef_before = coef_bands[last_true_indices, rows, cols]\n",
    "\n",
    "    nan_mask = np.isnan(out_coef_after)\n",
    "    out_coef_after[nan_mask] = out_coef_before[nan_mask]\n",
    "    return out_coef_after\n",
    "\n",
    "def getCoef(ccd_names, ccd_results, date, band_list, coef, startBands_indices, endBands_indices):\n",
    "  coefs= [filterCoefs(ccd_names, ccd_results, date, band, coef, startBands_indices, endBands_indices) for band in band_list]\n",
    "  return np.stack(coefs, axis=-1) if len(band_list) > 1 else coefs[0]\n",
    "\n",
    "def getMultiCoefs(ccd_names, ccd_results, date, band_list, coef_list, cond, seg_names, behavior, startBands_indices, endBands_indices):\n",
    "    # This function will use the previously converted getCoef and filterCoefs functions\n",
    "    out_coefs = [getCoef(ccd_names, ccd_results, date, band_list, coef,  startBands_indices, endBands_indices) for coef in coef_list]\n",
    "    out_coefs = np.stack(out_coefs, axis=-1)\n",
    "    return out_coefs\n",
    "\n",
    "\n",
    "def getSyntheticForYear(ccd_names, image, date,  bands, segs, startBands_indices, endBands_indices):\n",
    "  print('******************** getting data for year {} ******************'.format(date))\n",
    "  # Constants\n",
    "  PI2 = 2.0 * np.pi\n",
    "  omega = PI2\n",
    "\n",
    "  # Convert date to a numeric format (e.g., days since some reference date)\n",
    "  tfit = date\n",
    "  # Create synthetic image (array in this case)\n",
    "  image_t = np.array([[1], [tfit], [np.cos(tfit * omega)], [np.sin(tfit * omega)],\n",
    "                      [np.cos(tfit * omega * 2)], [np.sin(tfit * omega * 2)],\n",
    "                      [np.cos(tfit * omega * 3)], [np.sin(tfit * omega * 3)]]).astype(float)\n",
    "  image_t = image_t.T\n",
    "  COEFS = [\"INTP\", \"SLP\", \"COS\", \"SIN\", \"COS2\", \"SIN2\", \"COS3\", \"SIN3\"]\n",
    "  segnames = ['S'+ str(t) for t in segs]\n",
    "  new_params = getMultiCoefs(ccd_names, image, date, bands, COEFS, False, segs, 'auto', startBands_indices, endBands_indices)\n",
    "\n",
    "  synthetic_result_bands= [np.tensordot(new_params[:,:,i,:], image_t, axes=([2],[1])) for i in range(new_params.shape[2])]\n",
    "  synthetic_result_bands = np.dstack(synthetic_result_bands)\n",
    "  return (synthetic_result_bands*10000).astype(np.int16)\n",
    "\n",
    "def getSyntheticMultiYears(ccd_names, image, dates, bandList, segs, startBands_indices, endBands_indices):\n",
    "  multi_bands_years = [getSyntheticForYear(ccd_names, image, date,  bandList, segs, startBands_indices, endBands_indices) for date in dates]\n",
    "  multi_bands_years= np.dstack(multi_bands_years)\n",
    "  multi_bands_years= np.moveaxis(multi_bands_years, -1, 0)\n",
    "  return multi_bands_years\n",
    "\n",
    "\"\"\"#### Define parallel function\"\"\"\n",
    "def ccdc2BandsVIsByYear(file_path):\n",
    "  start_time = time.time()\n",
    "\n",
    "  ccdImage = rasterio.open(file_path)\n",
    "  meta = ccdImage.meta\n",
    "  meta.update({\n",
    "      'dtype':'int16'\n",
    "      })\n",
    "  ccdImage = ccdImage.read()\n",
    "  #ccdImage = ccdImage/10000\n",
    "  print(ccdImage.shape)\n",
    "  startBands_indices, endBands_indices = precompute_indices(ccd_names)\n",
    "  syn_bands = getSyntheticMultiYears(ccd_names, ccdImage, dates,  bands, segs, startBands_indices, endBands_indices)\n",
    "  #syn_bands = syn_bands*10000\n",
    "  if calculateVIs:\n",
    "    allBands = bands + VIs\n",
    "    band_names= [\"Year_\" + (str(year))[:4] +'_' + band for year in dates for band in allBands]\n",
    "  else:\n",
    "    band_names= [\"Year_\" + (str(year))[:4] +'_' + band for year in dates for band in bands]\n",
    "\n",
    "  years = [str(year)[:4] for year in dates]\n",
    "  for year in years:\n",
    "    bands_indices = [i for i, name in enumerate(band_names) if str(year) in name]\n",
    "    year_syn_bands = syn_bands[bands_indices,...]\n",
    "    meta.update(count= year_syn_bands.shape[0])\n",
    "    out_name = 'Summer_Year_'+ str(year) + '_'+ 'Bands_' + (file_path.split('/'))[-1].split('_')[-1]\n",
    "    year_band_names = [band_names[i] for i in bands_indices]\n",
    "    year_band_names = [nm[10:] for nm in year_band_names]\n",
    "    output_path = os.path.join(out_path, out_name)\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "      dst.write(year_syn_bands)\n",
    "      dst.descriptions= year_band_names\n",
    "  print('time to complete: {} minutes'.format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c0b2e-5ab9-4396-b5db-37235a33b382",
   "metadata": {},
   "source": [
    "#### Among all the functions above, ccdc2BandsVIsByYear is the wrapper function and the input is supposed to be a geotiff with fitted CCDC coefficents. Function getSyntheticMultiYears is a key function that takes all relevant parameters as input and then return spectral features for a given date. The output is synthethic reflectance value in a integer format with scalar factor of 10000. A detailed description on all input parameters for function getSyntheticMultiYears is described below. \n",
    "1. ccd_names: a list of string to indicates names of different bands of downloaded CCDC parametrs;\n",
    "2. image: 3D numpy array for the CCDC parameters, 1st dimension is for band;\n",
    "3. dates: float, date to derive spectral feature, e.g., 2024.5 means mid of year 2024;\n",
    "4. bandList: list of string to indicate names of bands to derive spectral features, e.g. [\"BLUE\", \"GREEN\", \"RED\", \"NIR\", \"SWIR1\", \"SWIR2\"];\n",
    "5. segs: list of string to indicate names of each segment, e.g. [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"S10\", \"S11\", \"S12\", \"S13\", \"S14\", \"S15\"]\n",
    "; \n",
    "6. startBands_indice and 7.  endBands_indice: derived by ccdc2BandsVIsByYear function based on band names of downloaded CCDC parameters.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0068f-5eb2-4513-a12a-f5aabc973791",
   "metadata": {},
   "source": [
    "### Example to apply the wrapper function to calculate spectral features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a60d03-8d55-41c1-9a4f-759d247e0821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019.5808219178082, 2020.5819672131147]\n"
     ]
    }
   ],
   "source": [
    "ccd_names =  pd.read_csv('CCDC_names_new.csv')\n",
    "ccd_names = list(ccd_names['CCDC_names'])\n",
    "bands = [\"BLUE\", \"GREEN\", \"RED\", \"NIR\", \"SWIR1\", \"SWIR2\"]\n",
    "segs = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"S10\", \"S11\", \"S12\", \"S13\", \"S14\", \"S15\"]\n",
    "out_path = '/ts_output/'\n",
    "\n",
    "# Here an example to calculate mid of year spectral features for 2019 and 2020\n",
    "years = [2019, 2020]\n",
    "dates = []\n",
    "for year in years:\n",
    "    if year % 4 == 0:\n",
    "        dates.append(year + 213/366)\n",
    "    else:\n",
    "        dates.append(year + 212/365)\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5ccf9-f70b-4f2d-ab05-e71a2f4933c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdc2BandsVIsByYear('CCDC_ts.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186de7c-97f7-4f36-90c3-f943d89d829b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2: Variable selection and parameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455625a-d2fa-4351-a551-6cb275de717e",
   "metadata": {},
   "source": [
    "### Define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa855ce-98b0-4093-a5bc-fe2ef7bfb1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# variable selection function using xgbm and recursive feature selection\n",
    "def xgbm_var_sel(dt_x, dt_y, n_top=35):\n",
    "    rf =  XGBRegressor(max_depth=14, min_child_weight=2, n_estimators=200, n_jobs=20, learning_rate=0.03, method='approx', max_bin = 250)\n",
    "    selector = RFE(estimator=rf, n_features_to_select=n_top, step=2)\n",
    "    selector = selector.fit(dt_x, dt_y)\n",
    "    \n",
    "    # Get the ranking of features\n",
    "    ranking = selector.ranking_\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    feature_ranking = pd.DataFrame({'Feature': dt_x.columns, 'Ranking': ranking})\n",
    "    feature_ranking = feature_ranking.sort_values(by='Ranking')\n",
    "    \n",
    "    return list(feature_ranking['Feature'])[:n_top]\n",
    "    \n",
    "def train_evaluate(x_tr, x_val, y_tr, y_val, n_tree, max_depth, lr, sub_sp, tree_method, max_bin, colsample):\n",
    "    \n",
    "  fit_md=   XGBRegressor( n_estimators=n_tree, max_depth=max_depth, learning_rate= lr,  colsample_bytree= colsample,subsample= sub_sp, tree_method=tree_method, max_bin=max_bin).fit(x_tr, y_tr)\n",
    "  pred_val = fit_md.predict(x_val)\n",
    "  f1_val= explained_variance_score(y_val, pred_val)\n",
    "  #f1_val= -np.mean(abs(fit_md.predict(x_val) - np.array(y_val['Lidar_AGB'])))\n",
    "  return f1_val\n",
    "\n",
    "def objective(trial=20):\n",
    "    params = {\n",
    "             'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "              'n_tree': trial.suggest_int(\"n_tree\", 100, 400, step=100),\n",
    "              'max_depth': trial.suggest_int(\"max_depth\", 4, 14, step=2),\n",
    "              'subsample': trial.suggest_float(\"subsample\", 0.4, 1.0, step=0.2),\n",
    "              'tree_method': trial.suggest_categorical('tree_method', ['exact', 'approx']),\n",
    "              'max_bin': trial.suggest_int('max_bin', 200, 250, step=50),\n",
    "              'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.4, 1, step=0.2)\n",
    "              }\n",
    "    n_tree = params['n_tree']\n",
    "    max_depth= params['max_depth']\n",
    "    sub_sp= params['subsample']\n",
    "    lr = params['learning_rate']\n",
    "    tree_method= params['tree_method']\n",
    "    max_bin= params['max_bin']\n",
    "    colsample = params['colsample_bytree']\n",
    "    accuracy= train_evaluate(x_tr, x_val, y_tr, y_val, n_tree, max_depth, lr, sub_sp, tree_method, max_bin, colsample)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae9f7d-a3cb-4b11-a41c-5a038e69a730",
   "metadata": {},
   "source": [
    "### Example to select 35 variables then fine tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393c34d-5077-4895-8224-dae71a68d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feas = xgbm_var_sel(dt_x, dt_y, n_top=35) # dt_x and dt_y are predictors and reponse from training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8be079-f6a1-4d61-be9b-7d9450134291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(dt_x[select_feas], dt_y, test_size=0.2)\n",
    "para_opt = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "para_opt.optimize(objective, n_trials=100, n_jobs=10)\n",
    "output = para_opt.trials_dataframe()\n",
    "output = output.sort_values(['value'], ascending=False).reset_index(drop=True)\n",
    "nm_out = 'Paramter_tunning_XGBM.csv'\n",
    "output.to_csv(nm_out , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad738a94-4c8e-491c-bd43-634f6afb63c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 3: Model training & saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae307b3-28de-4c0f-a994-f6f0511c0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncert_train_model(dt_train, i, xgbm_parameters_path = 'Paramter_tunning_XGBM.csv',y_variable_nm = 'AGB', selected_features= ['RED_summer','BLUE_summer','NDVI_summer'], model_out_path = ''):\n",
    "    \"\"\"\n",
    "    This code does the following tasks:\n",
    "    1) Simulates 3 types of uncertaties: sampling uncertainty using bootstrapping, allometry uncertainty, and CCDC/COLD uncertainty \n",
    "    2) train a XGBM regression with uncertainty-added data, \n",
    "    3) and save the model\n",
    "    Args:\n",
    "        dt_train: DataFrame containing the balanced training data,\n",
    "        i: integer to indicate which interation this run is, 0 means first itervation, n will be used in the name of the output model,\n",
    "        y_variable_nm: string to indicate column name for y variable,\n",
    "        selected_features: list of string to indicate name of features for model training,\n",
    "        model_out_path: string to indciate path where you want to save the trained model,\n",
    "        out_name: string to indicate name of the output model.\n",
    "\n",
    "    Returns:\n",
    "       no return, but save the trained model in given location\n",
    "    \"\"\"\n",
    "    \n",
    "    ## load training data using bootstrapping mehtod, bootsrapping_train is a self-defined function \n",
    "    random_state = n\n",
    "\n",
    "    ## Add allometry uncertainty in y variable using Monte Carlo to simulate normal-distributed random error\n",
    "    np.random.seed(random_state)\n",
    "    # column y_variable_nm+'_std' is the uncertainty, which is used as standard deviation of the normally distributed random error \n",
    "    dt_train['y_error'] = np.random.normal(loc=0, scale= dt_train[y_variable_nm+'_std'] , size = dt_train.shape[0])\n",
    "    dt_train['y2'] = dt_train['y_error'] + dt_train[y_variable_nm]\n",
    "\n",
    "    dt_x = dt_train[selected_features]\n",
    "    dt_y = dt_train[['y2']]\n",
    "\n",
    "    paras = pd.read_csv('Paramter_tunning_XGBM.csv')\n",
    "    model = XGBRegressor(n_estimators=paras['params_n_tree'].iloc[0], max_depth=paras['params_max_depth'].iloc[0], learning_rate=paras['params_learning_rate'].iloc[0], colsample_bytree=paras['params_colsample_bytree'].iloc[0], subsample=paras['params_subsample'].iloc[0], tree_method=paras['params_tree_method'].iloc[0], max_bin=paras['params_max_bin'].iloc[0],   n_jobs=10).fit(dt_x, dt_y)\n",
    "    out_name =  f'XGBM_model_out{i}.json'\n",
    "    model_path = model_out_path + '/' + out_name\n",
    "    model.save_model(model_path)\n",
    "    print(model_path + ' saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63824e4-fa67-412b-bd0f-aa0e8e28cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_sbb = bal_data_eco(eco)\n",
    "out_name2 = eco + '_Nccdc_uncert_'+ str(n) + 'F30b.json'\n",
    "uncert_train_model(dt_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30fa4c-77e7-43cf-8ecc-48f2347786d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 4: Model projection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9fe6c-b381-45e6-967f-07f935e42dee",
   "metadata": {},
   "source": [
    "#### Load key pacakges and define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ddfde-1a3f-4a1f-b655-29fdaecc493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np, pandas as pd, geopandas as gpd\n",
    "import rasterio\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "from xgboost import  XGBRegressor\n",
    "import xgboost as xgb\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import random\n",
    "\n",
    "\n",
    "def calculate_VIs_raster(image):\n",
    "    \"\"\"\n",
    "    This function computes vegetation indices.\n",
    "    Args:\n",
    "        image: numpy 3d array, with first dimension represents band. the code assumes 6 bands following below sequences: [\"BLUE\", \"GREEN\", \"RED\", \"NIR\", \"SWIR1\", \"SWIR2\"] \n",
    "\n",
    "    Returns:\n",
    "        numpy 3d array, with original input concated with computed vegetation indices\n",
    "    \"\"\"\n",
    "    eps = 0.00001\n",
    "    ##### NDVI #####\n",
    "    ndvi = (image[3,:,:] - image[2,:,:])/(image[3,:,:] + image[2,:,:]+ eps)\n",
    "    nbr = (image[3,:,:] - image[5,:,:])/(image[3,:,:] + image[5,:,:]+ eps)\n",
    "    # gndvi = (image[3,:,:] - image[1,:,:])/(image[3,:,:] + image[1,:,:]+ eps)\n",
    "    # ndwi = (image[1,:,:] - image[3,:,:])/(image[1,:,:] + image[3,:,:]+ eps)\n",
    "    msi = image[4,:,:]/(image[3,:,:]+ eps)\n",
    "    sr = image[3,:,:]/(image[2,:,:]+ eps)\n",
    "    # evi = 2.5*(image[3,:,:] - image[2,:,:]) / (image[3,:,:] + (6 * image[2,:,:]) - (7.5 * image[0,:,:]) + 1)\n",
    "    nbr2 = (image[4,:,:] - image[5,:,:])/(image[4,:,:] + image[5,:,:]+ eps)\n",
    "    #ndmi = (image[3,:,:] - image[4,:,:])/(image[3,:,:] + image[4,:,:])\n",
    "    ###### Tasseled Cap #####\n",
    "    coefficients = {\n",
    "          'brightness': [0.2043, 0.4158, 0.5524, 0.5741, 0.3124, 0.2303],\n",
    "          'greenness': [-0.1603, -0.2819, -0.4934, 0.7940, -0.0002, -0.1446],\n",
    "          'wetness': [0.0315, 0.2021, 0.3102, 0.1594, -0.6806, -0.6109]\n",
    "       }\n",
    "    # Applying the coefficients to the bands and summing them\n",
    "    brightness = np.sum([image[i,:,:] * coefficients['brightness'][i] for i in range(6)], axis=0)\n",
    "    greenness = np.sum([image[i,:,:] * coefficients['greenness'][i] for i in range(6)], axis=0)\n",
    "    wetness = np.sum([image[i,:,:] * coefficients['wetness'][i] for i in range(6)], axis=0)\n",
    "    image = np.concatenate((image,  ndvi.reshape(1, ndvi.shape[0], ndvi.shape[1]), \n",
    "                      msi.reshape(1, ndvi.shape[0], ndvi.shape[1]),  sr.reshape(1, ndvi.shape[0], ndvi.shape[1]), \n",
    "                      nbr2.reshape(1, ndvi.shape[0], ndvi.shape[1]),  nbr.reshape(1, ndvi.shape[0], ndvi.shape[1]),\n",
    "                      brightness.reshape(1, ndvi.shape[0], ndvi.shape[1]), greenness.reshape(1, ndvi.shape[0], ndvi.shape[1])), axis=0)\n",
    "    return image\n",
    "    \n",
    "\n",
    "def load_and_process_raster(file_path, name_suffix, anci_feas, spring_feas, early_summer_feas, mid_summer_feas, late_summer_feas, fall_feas):\n",
    "    \"\"\"\n",
    "    this function load predictors from geotiffs, and return selected features as a 3d numpy array, and a list of string including names of predictors.\n",
    "    \n",
    "    Args:\n",
    "        file_path: string, path of the predictor;\n",
    "        name_suffix: string, one of the below options ['_ancillary', '_spring', '_early_summer', '_late_summer', 'fall'], representing different predictors, i.e. ancillary or spectral features, and which season;\n",
    "        anci_feas: list, names of selected ancillary features;\n",
    "        spring_feas: list, names of selected spectral features from spring season;\n",
    "        early_summer_feas: list, names of selected spectral features from early summer season;\n",
    "        mid_summer_feas: list, names of selected spectral features from mid summer season;\n",
    "        late_summer_feas: list, names of selected spectral features from late summer season;\n",
    "        fall_feas: list, names of selected spectral features from fall season;\n",
    "    Returns:\n",
    "        a 3d numpy array with loaded features, and the features names in the array.\n",
    "    \"\"\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        print(name_suffix)\n",
    "        if not name_suffix == '_ancillary':\n",
    "            data = src.read() / 10000\n",
    "            data = calculate_VIs_raster(data)\n",
    "            feature_names = list(src.descriptions)\n",
    "            feature_names_n =[ 'NDVI', 'MSI', 'SR', 'NBR2', 'NBR', 'brightness', 'greenness']\n",
    "            feature_names = feature_names + feature_names_n\n",
    "            if not name_suffix == '_mid_summer':\n",
    "                feature_names = [nm + name_suffix for nm in feature_names]\n",
    "                \n",
    "            print(feature_names)\n",
    "            if name_suffix == '_spring':\n",
    "                keep_indexes = [feature_names.index(x) for x in spring_feas]\n",
    "                feas_nms = [feature_names[x] for x in keep_indexes]\n",
    "            elif name_suffix == '_early_summer':\n",
    "                keep_indexes = [feature_names.index(x) for x in early_summer_feas]      \n",
    "                feas_nms = [feature_names[x] for x in keep_indexes]\n",
    "            elif name_suffix == '_late_summer':\n",
    "                keep_indexes = [feature_names.index(x) for x in late_summer_feas]    \n",
    "                feas_nms = [feature_names[x] for x in keep_indexes]\n",
    "            elif name_suffix == '_fall':\n",
    "                keep_indexes = [feature_names.index(x) for x in fall_feas]  \n",
    "                feas_nms = [feature_names[x] for x in keep_indexes]\n",
    "            else:\n",
    "                keep_indexes = [feature_names.index(x) for x in mid_summer_feas]       \n",
    "                feas_nms = [feature_names[x] for x in keep_indexes]\n",
    "        else:\n",
    "            data = src.read() / 10000\n",
    "            anci_nms = list(src.descriptions) \n",
    "            keep_indexes = [anci_nms.index(x) for x in anci_feas]\n",
    "            feas_nms = [anci_nms[x] for x in keep_indexes]\n",
    "            \n",
    "        selected_data = data[keep_indexes,:,:]\n",
    "        del data\n",
    "        return selected_data, feas_nms\n",
    "    \n",
    "# Function to load model and make predictions\n",
    "def load_and_predict(eco_model_index, data_2d):\n",
    "    \"\"\"\n",
    "    This code load the saved model and make predictions on features.\n",
    "\n",
    "    Args:\n",
    "        eco_model_index: string, formatted as EcoregionName_ModelIndex, where EcoregionName is a string to indicate a particular ecoregion and ModelIndex is a integer to index unique id of the model for the ecoregion;\n",
    "        data_2d: numpy 2d array with shape number_of_pixel*number_of_features\n",
    "    \n",
    "    Returns:\n",
    "        return predicted AGB value * 100.\n",
    "    \"\"\"\n",
    "    \n",
    "    eco = eco_model_index.split('__')[0]\n",
    "    model_index = eco_model_index.split('__')[1]\n",
    "    model_path = f'/model_path/trained_MLs/{eco}_{model_index}.json'\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model(model_path)\n",
    "    return model.predict(data_2d)*100\n",
    "        \n",
    "def pred_landsat(tile_year_nrep_eco_outpath):\n",
    "    \"\"\"\n",
    "    This function is a wrapper function that predicts mean AGB and derive uncertainty for each tile, and then write the output as Cloud Optimized Geotiff.\n",
    "\n",
    "    Args:\n",
    "    tile_year_nrep_model: string, formatted as TileName_YearOfFeatures_NumberOfModels_EcoregionName_OutputPath.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    write AGB prediction and uncertainty as Cloud Optimized Geotiff.\n",
    "\n",
    "    \"\"\"\n",
    "    tile = tile_year_nrep_model.split('_')[0]\n",
    "    year = tile_year_nrep_model.split('_')[1]\n",
    "    n_reps = int(tile_year_nrep_model.split('_')[2])\n",
    "    eco = tile_year_nrep_model.split('_')[3]\n",
    "    out_path = tile_year_nrep_model.split('_')[4]\n",
    "    out_name = f'{eco}_AGB_Pred_Year_{year}_{tile}_{model}.tif'\n",
    "   \n",
    "    output_path = os.path.join(out_path, out_name)\n",
    "\n",
    "    def load_feas(eco, model):\n",
    "        model_path = f'model_path/trained_MLs/{eco}_0.json'\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.load_model(model_path)\n",
    "        return list(model.get_booster().feature_names)\n",
    "        \n",
    "    top_feature_names = load_feas(eco, model)\n",
    "    anciA = ['TEMPERATURE','RAINFALL', 'DEM_GLO30', 'slope_GLO30', 'aspect_GLO30']\n",
    "    anci_feas = [nm for nm in top_feature_names if nm in anciA]\n",
    "    spring_feas = [nm for nm in top_feature_names if '_spring' in nm]\n",
    "    early_summer_feas = [nm for nm in top_feature_names if '_early_summer' in nm]\n",
    "    late_summer_feas = [nm for nm in top_feature_names if '_late_summer' in nm]\n",
    "    fall_feas = [nm for nm in top_feature_names if '_fall' in nm]\n",
    "    mid_summer_feas = list(set(top_feature_names) - set(anci_feas + spring_feas + early_summer_feas + late_summer_feas+fall_feas))\n",
    "    \n",
    "    mid_summer = f'spectral_feature_path/mid_summer_bands/Summer_Year_{year}_Bands_{tile}_Merged.tif'\n",
    "    seasons = {\n",
    "        \"ancillary\": f'ancillary_feature_path/Ancillary_{tile}_Merged.tif',\n",
    "        \"spring\": f'spectral_feature_path/spring_bands/Spring_Year_{year}_Bands_{tile}_Merged.tif',\n",
    "        \"early_summer\": f'spectral_feature_path/early_summer_bands/Early_Summer_Year_{year}_Bands_{tile}_Merged.tif',\n",
    "        \"mid_summer\": f'spectral_feature_path/mid_summer_bands/Summer_Year_{year}_Bands_{tile}_Merged.tif',\n",
    "        \"late_summer\": f'spectral_feature_path/late_summer_bands/Late_Summer_Year_{year}_Bands_{tile}_Merged.tif',\n",
    "        \"fall\": f'spectral_feature_path/fall_bands/Fall_Year_{year}_Bands_{tile}_Merged.tif'\n",
    "    }\n",
    "    \n",
    "    lc = f'land_cover_path/Year_{year}_{tile}_Merged.tif'\n",
    "    \n",
    "\n",
    "    if os.path.exists(output_path)& skip:\n",
    "        print('skipping')\n",
    "    else:\n",
    "        print(\"Reading and processing ancillary and seasonal rasters\")        \n",
    "        with ThreadPoolExecutor(6) as executor:\n",
    "            future_results = {season: executor.submit(load_and_process_raster,  file_path,  f\"_{season}\", anci_feas, spring_feas , early_summer_feas, mid_summer_feas, late_summer_feas, fall_feas)\n",
    "                              for season, file_path in seasons.items()}\n",
    "            seasonal_data = {season: future.result() for season, future in future_results.items()}\n",
    "\n",
    "        seasonal_arrays = [data for data, _ in seasonal_data.values()]    \n",
    "        seasonal_names = [name for _, name in seasonal_data.values()]\n",
    "        seasonal_names = [name for sublist in seasonal_names for name in sublist]\n",
    "\n",
    "        indices = [seasonal_names.index(item) for item in top_feature_names]\n",
    "\n",
    "        geo_array = np.concatenate(seasonal_arrays, axis=0)\n",
    "        del seasonal_arrays\n",
    "        geo_array = geo_array[indices,:,:]\n",
    "                    \n",
    "        #print(len(top_feature_names))\n",
    "        # Reshape for model input\n",
    "        height, width = geo_array.shape[1], geo_array.shape[2]\n",
    "        data_2d = geo_array.transpose(1, 2, 0).reshape(-1, len(top_feature_names))\n",
    "        del geo_array\n",
    "        # Predict using pre-trained models\n",
    "        all_predictions = np.zeros((n_reps, data_2d.shape[0]), dtype=np.int32)\n",
    "        \n",
    "        \n",
    "        # Use ThreadPoolExecutor to parallelize the prediction for each model\n",
    "        model_indices = [eco + '__' + str(i) + model for i in range(n_reps)]\n",
    "        with ThreadPoolExecutor(max_workers= 10) as executor:\n",
    "            futures = {executor.submit(load_and_predict, j, data_2d): j for j in model_indices}\n",
    "            for future in as_completed(futures):\n",
    "                j = futures[future]\n",
    "                j = int(j.split('__')[1][:-3])\n",
    "                try:\n",
    "                    all_predictions[j, :] = future.result()\n",
    "                except Exception as exc:\n",
    "                    print(f\"Model {j} generated an exception: {exc}\")\n",
    "        \n",
    "        # Calculate outputs and uncertainties\n",
    "        predicted_rasters = np.mean(all_predictions, axis=0).reshape(height, width)\n",
    "        predicted_std = np.std(all_predictions, axis=0).reshape(height, width)\n",
    "        #percent_uncertainty = (predicted_std / np.maximum(predicted_rasters, 1e-6)) * 100\n",
    "        out_all = np.stack((predicted_rasters, predicted_std), axis=0)\n",
    "        #out_all = out_all*100\n",
    "\n",
    "        print('post processing')\n",
    "        if os.path.exists(lc)&(eco!='TUNDRA'):\n",
    "            lc_src = rasterio.open(lc)\n",
    "            lc_ra = lc_src.read(1)\n",
    "            nodata_value_raster = lc_src.nodata\n",
    "            nodata_locations = np.where(lc_ra == nodata_value_raster, True, False)\n",
    "            out_all[:,(lc_ra == 1) | (lc_ra == 7)| (lc_ra == 9)] = 0\n",
    "            out_all[:,lc_ra==0] = -999\n",
    "        out_all[(out_all < 0) & (out_all > -990)] = 0\n",
    "\n",
    "        # Write output raster\n",
    "        print(\"Writing output raster\")\n",
    "        meta = rasterio.open(mid_summer).meta\n",
    "        meta.update(count=out_all.shape[0], nodata=-999)\n",
    "        meta.update({\n",
    "          \"driver\": \"COG\",\n",
    "          \"dtype\": \"int32\",\n",
    "          'compress': 'lzw',\n",
    "          'blockxsize': 512,\n",
    "          'blockysize': 512,\n",
    "          \"tiled\": True,\n",
    "          \"interleave\": \"band\"})\n",
    "        output_path = os.path.join(out_path, out_name)\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(out_all)\n",
    "            dst.descriptions = ['pred_AGB', 'pred_std']\n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57013c7-54b6-420f-aefe-57d37badf452",
   "metadata": {},
   "source": [
    "#### Example code to derive AGB and uncertainty predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b0cd8-a406-4095-8a27-358db777ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_landsat('Bh008v015_2020_50_NWFM_/Landsat_prediction/output') # NWFM: Northwestern Forested Mountains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab363c0-69ec-4ea3-b888-5a45403b01a0",
   "metadata": {},
   "source": [
    "## Step 5: Post processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e7b29-dedd-4501-be3b-4adb54b8784a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 6: Quality flag layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a1bb6-4169-447f-a554-c2105128f0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
